{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Lesson\n",
    "#### Ben Wilson\n",
    "\n",
    "## Supervised Learning Model Steps\n",
    "When building a supervised model (like regression or classification) there is a general methodology you'd like to follow.\n",
    "\n",
    "1) Gather the data set with predictor variables and the target variable to predict in the future.\n",
    "2) Split the data set into training and testing data. Typically a 70 - 30 split.\n",
    "3) Build the model based on the training data.\n",
    "4) Try out the model with the data set aside for testing.\n",
    "5) Fine tune your model using cross-validation to improve predictive accuracy.\n",
    "6) Predict unkown data!\n",
    "\n",
    "## Where to watch out for overfitting...\n",
    "Overfitting can happen in steps 2 through 4. \n",
    "\n",
    "If you do not split your data set into training and testing, your model will be inheriently too optimistic. You have optimized just for that given set of data.\n",
    "\n",
    "A similar pitfall can happen if you try to optimize just on the training data. The training data helps keep your model in check.\n",
    "\n",
    "Also, sometimes the simplier models do a better job predicting than polynomic models that are too fitted to the current data set.\n",
    "\n",
    "## Walkthrough example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed for reporducible results\n",
    "np.random.seed(414)\n",
    "\n",
    "# Generate toy data\n",
    "X = np.linspace(0, 15, 1000)\n",
    "y = 3 * np.sin(X) + np.random.normal(1 + X, .2, 1000)\n",
    "\n",
    "train_X, train_y = X[:700], y[:700]\n",
    "test_X, test_y = X[700:], y[700:]\n",
    "\n",
    "train_df = pd.DataFrame({'X': train_X, 'y': train_y})\n",
    "test_df = pd.DataFrame({'X': test_X, 'y': test_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add in a small helper funtion\n",
    "from IPython.core.display import HTML\n",
    "def short_summary(est):\n",
    "    return HTML(est.summary().tables[1].as_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.9959</td> <td>    0.152</td> <td>   13.104</td> <td> 0.000</td> <td>    1.697     2.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>         <td>    0.8896</td> <td>    0.025</td> <td>   35.405</td> <td> 0.000</td> <td>    0.840     0.939</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Fit\n",
    "poly_1 = smf.ols(formula='y ~ 1 + X', data=train_df).fit()\n",
    "short_summary(poly_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.1458</td> <td>    0.221</td> <td>   14.261</td> <td> 0.000</td> <td>    2.713     3.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>         <td>    0.2313</td> <td>    0.097</td> <td>    2.382</td> <td> 0.017</td> <td>    0.041     0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(X ** 2)</th> <td>    0.0627</td> <td>    0.009</td> <td>    7.004</td> <td> 0.000</td> <td>    0.045     0.080</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quadratic Fit\n",
    "poly_2 = smf.ols(formula='y ~ 1 + X + I(X**2)', data=train_df).fit()\n",
    "short_summary(poly_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the quadratic regression performs better than the linear regression with the training data.\n",
    "\n",
    "The quadratic regression has a lower confidence interval and standard error.\n",
    "\n",
    "I suspect when we run the test data through it, the quadratic will not predict the target variable as well as the linear regression.\n",
    "\n",
    "__How do I run the test data set through the model I just created and optimized for?__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
